import pytest
from query_data import query_rag
from langchain_community.llms.ollama import Ollama


# Prompt d'√©valuation LLM
EVAL_PROMPT = """
Tu es un √©valuateur rigoureux. On te donne une r√©ponse attendue et une r√©ponse r√©elle √† une m√™me question.

Ta mission est de dire si la r√©ponse r√©elle fournit bien l'information demand√©e, m√™me si elle est formul√©e diff√©remment.

Expected Response: {expected_response}
Actual Response: {actual_response}
---
R√©ponds uniquement par 'true' ou 'false'. Est-ce que la r√©ponse r√©elle correspond bien √† ce qui √©tait attendu ?
"""

# Initialisation du mod√®le LLM via Ollama
llm = Ollama(model="MISTRALCHATBOT")

# Fonction d'√©valuation avec LLM
def validate_with_llm(expected, actual):
    prompt = EVAL_PROMPT.format(expected_response=expected, actual_response=actual)
    result = llm.invoke(prompt).strip().lower()
    print(f"\nüß™ Prompt LLM :\n{prompt}\nüì§ R√©sultat LLM : {result}")
    if "true" in result:
        return True
    elif "false" in result:
        return False
    raise ValueError("R√©ponse LLM invalide (ni true ni false)")

# --------- ‚úÖ TESTS POSITIFS ---------

@pytest.mark.parametrize("question, expected_response", [
    (
        "Quel type d‚Äôextincteur faut-il pour une station-service avec carburant liquide ?", 
        "Un extincteur de 9kg √† poudre est requis pour chaque ilot de distribution."
    ),
    (
        "Quelle est la port√©e d‚Äôun jet droit avec un RIA DN25-30 ?", 
        "Le jet droit atteint 13,5 m√®tres pour un RIA DN25-30."
    ),
    (
        "Quels additifs ne peuvent pas √©teindre un feu de solvant polaire ?", 
        "SC-6, VALEXT, ECOPOL, FFX Compact et FFX Booster A ne sont pas efficaces contre les feux de solvant polaire."
    ),
])
def test_llm_response_true(question, expected_response):
    actual_response = query_rag(question)
    assert validate_with_llm(expected_response, actual_response)


# --------- ‚ùå TESTS N√âGATIFS ---------

@pytest.mark.parametrize("question, wrong_expectation", [
    (
        "Un extincteur √† mousse est-il suffisant pour le carburant GPL ?", 
        "Oui, un extincteur √† mousse suffit pour le carburant GPL."
    ),
    (
        "Quelle est la port√©e d‚Äôun jet droit avec un RIA DN10-90 ?", 
        "Il atteint 25 m√®tres."
    ),
    (
        "Peut-on utiliser les additifs SC-6 pour √©teindre un feu d‚Äôessence ?", 
        "Oui, ils sont parfaitement efficaces sur les feux de solvants polaires."
    ),
])
def test_llm_response_false(question, wrong_expectation):
    actual_response = query_rag(question)
    assert not validate_with_llm(wrong_expectation, actual_response)
